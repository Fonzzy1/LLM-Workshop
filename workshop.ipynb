{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fonzzy1/LLM-Workshop/blob/main/workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "execute:\n",
        "  cache: true\n",
        "jupyter: python3\n",
        "\n",
        "---\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/Fonzzy1/LLM-Workshop/blob/main/workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "# **LLMs for Communications Methods**\n",
        "##### Presented at the ADM+S 2026 Summer School as the interactive component of\n",
        "# **Integrating LLMs into communication research methods: Possibilities, assumptions and risks**\n",
        "\n",
        "\n",
        "This session will provide users with a hands-on opportunity to see how language models can be integrated into communications research, and what possibilities and risks this presents.\n",
        "\n",
        "<br>\n",
        "\n",
        "*Authors: Alfie Chadwick and Laura Vodden*\n"
      ],
      "metadata": {
        "id": "c0YJtji_H6Hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# **üî® Part 1. Setting up**\n"
      ],
      "metadata": {
        "id": "G_NGhqTQIEms"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz2ZFk9OhZRk"
      },
      "source": [
        "‚ô¶\n",
        "\n",
        "### **1.1 Housekeeping**\n",
        "\n",
        "**Before you proceed**\n",
        "\n",
        "The default runtime type of Colab instances is CPU based. We will need to change our runtime type to **T4 GPU** or better.\n",
        "Change this by either going to **Runtime > Change runtime type**\n",
        "\n",
        "*or*\n",
        "\n",
        "by going to the tiny arrow in the top right corner of your browser and selecting **Change runtime type**.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "You should now see ![image.png](data:image/png;base64,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) in the bottom right corner of your browser.\n",
        "\n",
        "Source [here](https://colab.research.google.com/github/5aharsh/collama/blob/main/Ollama_Setup.ipynb#scrollTo=o2ghppmRDFny).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ô¶\n",
        "\n",
        "### **1.2 Using Colab Notebooks**\n",
        "\n",
        "As we work through this notebook, we will run each code cell consecutively. When you mouse over each code block, a ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABUAAAATCAIAAADwLNHcAAABoklEQVR4AZyUP6/BUBjGb5qIL2CxuZtZLDZhY7CJGGwWm8SEEZPEZrFJiNgMbMQmuRGrka1Lv0DT4d7fcZrXuW0ZnLx5Pe/zp+dUqfUbWovFol6vp9Pp78cCMEKGjIqwvoy13+8LhUK/3z+dTq7ragXACImEQZPSn/nlctlsNu/3u2gBgIQBm8n7eS7MDqbwCmPDLKqfHw6HQgFKpVI2mwVElmlWeY7E2QLW9Xo9Go2SyWSAZ8RMBECp/Ha7BYWrVqsdj8dWqxWWJKLyl8sl7NBMLBbrdDrccKVS0YzuErEcx+EJafZV53cwmUzm87l8KUQI4lf78/FxWYlEIh6Pv8/fbrd2u91oNM7ns3YSIQhW+2cyGVBkeZ43Ho+LxeJmszENElH5crlsaoJXq1U+n59Op8IIkIjK8/dIpVKiaVCtVrvdrm3bejQ7ZiKaUXlQr9ejS+12O7lVIQWYZj/PHQ4GA3G8Adgwi8HPM3Ok2WzG2cCRhYQBm6k+87Bc+HA4sEMul+MJwVAARkgkDDBm/ctrgR1421yv15/HAjBCajXQ/wAAAP//mBgSfAAAAAZJREFUAwAxatRwDuTLewAAAABJRU5ErkJggg==) button will appear in the top left corner of that cell. **Clicking** this will **run the code** in that cell.\n",
        "\n",
        "Once the code has finished running, you will see a green tick and the time taken to run the code beside this button:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "**Hint:** Look for the üèÉ emoji to know which cells to run.\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "BvFKBrU3X9lX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ú¥\n",
        "\n",
        "### **1.3 Set up ollama environment, and install and import libraries**\n",
        "This should only take a minute or two."
      ],
      "metadata": {
        "id": "IeBqlYUvIBbw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekAWDj4dhZRp",
        "outputId": "b88cd6c6-c0e6-4985-8290-f8a0c9ee11f9"
      },
      "source": [
        "#| eval: false\n",
        "!sudo apt update\n",
        "!sudo apt install -y pciutils zstd\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!pip install ollama kagglehub kagglehub[pandas-datasets] pandas\n",
        "\n",
        "# Fancy little subprocess trick to get ollama working in Colab workbooks\n",
        "# import subprocess\n",
        "# proccess = subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, stdin=subprocess.DEVNULL, close_fds=True)\n",
        "import ollama\n",
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def ollama_thread_function():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=ollama_thread_function)\n",
        "ollama_thread.start()\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\u001b[0m\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "119 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "pciutils is already the newest version (1:3.7.0-6).\n",
            "zstd is already the newest version (1.4.8+dfsg-3build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 119 not upgraded.\n",
            ">>> Cleaning up old version at /usr/local/lib/ollama\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading ollama-linux-amd64.tar.zst\n",
            "######################################################################## 100.0%\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "Requirement already satisfied: ollama in /usr/local/lib/python3.12/dist-packages (0.6.1)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.12/dist-packages (from ollama) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.12/dist-packages (from ollama) (2.12.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (26.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21j6BkqPhZRr"
      },
      "source": [
        "‚ú¥\n",
        "\n",
        "### **1.4 Model selection**\n",
        "\n",
        "We are going to be using **four** Large Language Models today:\n",
        "* Llama\n",
        "* Qwen\n",
        "* Gemma\n",
        "* Deepseek\n",
        "\n",
        "\n",
        "\n",
        "All of these models are **open source**, and all but Gemma are the same size.  \n",
        "However, they will exhibit slight differences when we ask them the same\n",
        "question.\n",
        "\n",
        "For other models check https://ollama.com/library\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "> üèÉ **Run the cell below** to 'pull' our models from the ollama library. This could take up to 4 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv2PRwgThZRs",
        "outputId": "c4fe8921-ac83-470d-8009-0a70fc25baa8"
      },
      "source": [
        "!ollama pull llama3.1:8b\n",
        "!ollama pull qwen3:8b\n",
        "!ollama pull gemma3:4b\n",
        "!ollama pull deepseek-r1:8b\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# models = ['llama3.1:8b', 'qwen3:8b', 'gemma3:4b', 'deepseek-r1:8b']\n",
        "# for model in models:\n",
        "#   os.system(f\"ollama pull {model}\")\n",
        "#   print(f\"loading {model}\")\n"
      ],
      "metadata": {
        "id": "CtMFaMd5XJJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**While this runs:**\n",
        "\n",
        "‚úã Does anybody need any assitance?\n",
        "\n",
        "‚úã Are there any concepts/jargon we should clarify?"
      ],
      "metadata": {
        "id": "jP8E5ouizuCt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n27ifgX9hZRt"
      },
      "source": [
        "---\n",
        "‚ú¥\n",
        "\n",
        "# **ü§ñ Part 2. Interacting with LLMs in Python**\n",
        "\n",
        "Unlike interacting with a chat client online, using LLMs in Python is much more\n",
        "flexible but takes a little time to set up.\n",
        "\n",
        "In Python we can create **functions** - repeatable pieces of code using the `def`\n",
        "syntax. We can pass **arguments** to these functions, which change how the function behaves.\n",
        "\n",
        "Below is a function that takes two arguments:\n",
        "\n",
        "1. a **prompt** (```prompt```); and\n",
        "    \n",
        "2. the name of the **model** we want to use (```mymodel```)\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "> üèÉ **Run the cell below** to **define** the **function**. This will not 'do' anything yet, but we will **call** this function later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBMa9jbNhZRu"
      },
      "source": [
        "def query_llm(prompt, mymodel):\n",
        "\n",
        "    # send the request with prompt and mymodel to ollama and get the full response\n",
        "    response = ollama.chat(\n",
        "        model=mymodel,\n",
        "        messages=[{\"role\": \"user\",\n",
        "                   \"content\": prompt}\n",
        "                  ]\n",
        "    )\n",
        "    # extract response text from response\n",
        "    response_text = response.message.content\n",
        "\n",
        "    # return model text\n",
        "    return response_text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_z4ShjdhZRv"
      },
      "source": [
        "‚ô¶\n",
        "\n",
        "### **2.1 Running the LLMs**\n",
        "Now that we have **defined** a working **function**, we need to define our **prompt** and **model** selection.\n",
        "\n",
        "<br>\n",
        "\n",
        "> ‚úç Change the **prompt** in the cell below to something that is within your field of expertise - but try to ask for a brief response. Or, use one of the existing ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qByzI7QchZRw"
      },
      "source": [
        "# Examples (ctrl+/ to use):\n",
        "# prompt = 'What is the role of performance in australian parliamentary debates'\n",
        "# prompt = 'Briefly tell me: What does a cat say?'\n",
        "prompt = 'In 100 words or less: What is the definition of framing in communication science?'\n",
        "\n",
        "# prompt = 'YOUR OWN PROMPT HERE'\n",
        "\n",
        "print(f'Your prompt:\\n\\n {prompt}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "> üèÉ **Run the cell below** to create a list of our **models**."
      ],
      "metadata": {
        "id": "gSwD5QLpeVnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select models\n",
        "models = ['llama3.1:8b', 'qwen3:8b', 'gemma3:4b', 'deepseek-r1:8b']\n",
        "\n",
        "print(f'Your models:\\n\\n {models}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI42C0ExeN_e",
        "outputId": "5afaaec9-e767-4c9f-f08a-d0e1c52d3f65"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your models:\n",
            "\n",
            " ['llama3.1:8b', 'qwen3:8b', 'gemma3:4b', 'deepseek-r1:8b']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP7PvA6xhZRx"
      },
      "source": [
        "We can now go and ask what each **model** says in response to our **prompt** using the **function** that\n",
        "was defined above.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "> üèÉ **Run the cell below** to **call** the function. Notice that we iterate through each `model` in the list, and pass the **same prompt** to each one as a `prompt` argument. The function **returns** a separate **response** each time, based on the `model` and `prompt` arguments. This may take up to 2 minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "\n",
        "# pass the prompt to each model in the list\n",
        "for mymodel in models:\n",
        "    print(f\"{mymodel} is analysing your question...\\n\")\n",
        "\n",
        "    response_text = query_llm(prompt, mymodel)\n",
        "\n",
        "    rows.append({\n",
        "        \"model\": mymodel,\n",
        "        \"response\": response_text\n",
        "    })\n",
        "\n",
        "test_df = pd.DataFrame(rows)\n",
        "\n",
        "test_df"
      ],
      "metadata": {
        "id": "bUMNPSdCqTBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**While this runs:**\n",
        "\n",
        "‚úã Does anybody need any assitance?\n",
        "\n",
        "‚úã Are there any concepts/jargon we should clarify?"
      ],
      "metadata": {
        "id": "PJGBxGLTbcI6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ú¥\n",
        "\n",
        "### **2.2 Visualising the outputs**\n",
        "\n",
        "Let's have a look at the data. Does the response **length** very by model?\n",
        "\n",
        "> üèÉ **Run the cell below** to **plot** response length by model."
      ],
      "metadata": {
        "id": "qXW7pjqjE9ZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# compute word counts for each model\n",
        "word_counts = test_df.set_index('model')['response'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# plot\n",
        "word_counts.plot(kind=\"bar\", figsize=(8,5))\n",
        "plt.ylabel(\"response word count\")\n",
        "plt.title(\"answer length (n words) by model\\n\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o9qJJrWe1A_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> üèÉ **Run the cell below** to **plot** a word cloud for each model."
      ],
      "metadata": {
        "id": "qqt0ojymk1sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "from matplotlib.patches import Rectangle\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Simple stopword list\n",
        "stop_words = {\n",
        "    \"the\", \"and\", \"of\", \"e\", \"g\", \"vs\", \"to\", \"s\", \"a\", \"in\", \"is\", \"it\", \"that\", \"as\",\n",
        "    \"for\", \"with\", \"on\", \"by\", \"this\", \"are\", \"or\", \"an\", \"be\",\n",
        "    \"from\", \"at\", \"which\", \"but\", \"not\", \"have\", \"has\", \"their\",\n",
        "    \"its\", \"also\", \"can\", \"how\", \"such\", \"frame\", \"framing\", \"frames\"\n",
        "}\n",
        "\n",
        "top_n = 10\n",
        "rows = []\n",
        "\n",
        "for _, row in test_df.iterrows():\n",
        "    model = row[\"model\"]\n",
        "    text = str(row[\"response\"]).lower()\n",
        "\n",
        "    # Extract words\n",
        "    words = re.findall(r\"\\b[a-zA-Z]+\\b\", text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    words = [w for w in words if w not in stop_words]\n",
        "\n",
        "    # Count top words\n",
        "    counts = Counter(words).most_common(top_n)\n",
        "\n",
        "    for rank, (word, count) in enumerate(counts, start=1):\n",
        "        rows.append({\n",
        "            \"model\": model,\n",
        "            \"rank\": rank,\n",
        "            \"word\": word,\n",
        "            \"count\": count,\n",
        "            \"word_count\": f\"{word} ({count})\"   # convenient display column\n",
        "        })\n",
        "\n",
        "# Create dataframe\n",
        "top_words_df = pd.DataFrame(rows)\n",
        "\n",
        "# Pivot to horizontal format\n",
        "wide_df = top_words_df.pivot(index='model', columns='rank', values='word_count')\n",
        "wide_df.columns = [f\"top_{col}\" for col in wide_df.columns]\n",
        "wide_df.reset_index(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Iterate over each model and make a word cloud\n",
        "models = top_words_df[\"model\"].unique()\n",
        "plt.figure(figsize=(5 * len(models), 4))\n",
        "\n",
        "for i, model in enumerate(models, 1):\n",
        "    # Build frequency dictionary: {word: count}\n",
        "    top_words = (\n",
        "        top_words_df[top_words_df[\"model\"] == model]\n",
        "        .set_index(\"word\")[\"count\"]\n",
        "        .to_dict()\n",
        "    )\n",
        "\n",
        "    ax = plt.subplot(1, len(models), i)\n",
        "    wc = WordCloud(\n",
        "        width=400,\n",
        "        height=300,\n",
        "        background_color=\"white\",\n",
        "        colormap=\"tab10\"\n",
        "    ).generate_from_frequencies(top_words)\n",
        "\n",
        "    ax.imshow(wc, interpolation=\"bilinear\")\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(model)\n",
        "\n",
        "    # Add border rectangle\n",
        "    rect = Rectangle(\n",
        "        (0, 0), 1, 1, transform=ax.transAxes,\n",
        "        fill=False, edgecolor=\"black\", linewidth=2\n",
        "    )\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "plt.suptitle(\"Top Words per Model\", fontsize=16, weight=\"bold\")\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.92])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xDClnN6q2Sx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üßê Questions**\n",
        "\n",
        "\n",
        "> *  What did the models get **right**, and what did they get **wrong**?\n",
        "> *  How did the response **differ** between the different models?\n",
        "> *  Which model gave the 'best' response, and **why** do you think that?\n",
        "> *  Is this kind of output **useful**?\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "fWUx31j3FEhX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRDTAz1xhZRy"
      },
      "source": [
        "---\n",
        "‚ô¶\n",
        "\n",
        "\n",
        "# **üìì Part 3. Using LLMs for communication research**\n",
        "\n",
        "While we can use LLMs for question-answering tasks, as we did before, they are particularly for the **'busy work'** of research.\n",
        "\n",
        "\n",
        "Tasks such as data **cleaning**, **labelling**, **classification** and **extraction** are relatively straightforward to automate and **validate**. By automating such processes, we can work with much larger datasets and address research questions at a different scale than would typically be feasible using manual methods.\n",
        "\n",
        "\n",
        "While these approaches enable new analytical **possibilities**, they also introduce **risks** that warrant careful consideration. We will keep this in mind as we work through the following examples.\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "### **‚òù Example: Narrative framing: Hero/villain extraction**\n",
        "\n",
        "In this demo, we're going to expand on the work done by [Frermann et al.\n",
        "(2023)](https://doi.org/10.18653/v1/2023.acl-long.486), which looks at how\n",
        "**narrative actors** - in this case, heroes, victims and villains - are allocated within climate\n",
        "discourse.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ô¶\n",
        "\n",
        "## **3.1 Dataset selection**\n",
        "\n",
        "Dataset selection is one of the most important parts of computational\n",
        "communications tasks as it defines the scope of questions that can be answered\n",
        "by your later analysis.\n",
        "\n",
        "Today, we are using pre-built **Twitter Climate Change Sentiment** dataset from\n",
        "[Kaggle](https://www.kaggle.com/datasets/edqian/twitter-climate-change-sentiment-dataset), for ease of access.\n",
        "\n",
        "This dataset contains a sample of **tweets**, with their **sentiment** towards climate change\n",
        "labeled as follows:\n",
        "\n",
        "\n",
        "- **2 (News):** the tweet links to factual news about climate change  \n",
        "- **1 (Pro):** the tweet **supports** the belief of anthropogenic climate change  \n",
        "- **0 (Neutral):** the tweet **neither supports nor refutes** the belief of anthropogenic\n",
        "  climate change  \n",
        "- -**1 (Anti):** the tweet **refutes** the belief of anthropogenic climate change\n",
        "\n",
        "<br>\n",
        "\n",
        "> üèÉ **Run the cell below** to import the dataset and view the first five records."
      ],
      "metadata": {
        "id": "gQCfJrbXHByw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duSpYU-0hZRy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "0083e042-b6e1-4535-d7af-84ce381e96fa"
      },
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Set the path to the file you'd like to load\n",
        "file_path = \"twitter_sentiment_data.csv\"\n",
        "\n",
        "# Load the latest version\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"edqian/twitter-climate-change-sentiment-dataset\",\n",
        "  file_path,\n",
        ")\n",
        "\n",
        "print(\"First 5 records:\\n\")\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-404345684.py:8: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'twitter-climate-change-sentiment-dataset' dataset.\n",
            "First 5 records:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sentiment  \\\n",
              "0         -1   \n",
              "1          1   \n",
              "2          1   \n",
              "3          1   \n",
              "4          2   \n",
              "\n",
              "                                                                                                                                              message  \\\n",
              "0           @tiniebeany climate change is an interesting hustle as it was global warming but the planet stopped warming for 15 yes while the suv boom   \n",
              "1  RT @NatGeoChannel: Watch #BeforeTheFlood right here, as @LeoDiCaprio travels the world to tackle climate change https://t.co/LkDehj3tNn htt√É¬¢√¢‚Äö¬¨√Ç¬¶   \n",
              "2                               Fabulous! Leonardo #DiCaprio's film on #climate change is brilliant!!! Do watch. https://t.co/7rV6BrmxjW via @youtube   \n",
              "3     RT @Mick_Fanning: Just watched this amazing documentary by leonardodicaprio on climate change. We all think this√É¬¢√¢‚Äö¬¨√Ç¬¶ https://t.co/kNSTE8K8im   \n",
              "4         RT @cnalive: Pranita Biswasi, a Lutheran from Odisha, gives testimony on effects of climate change &amp; natural disasters on the po√É¬¢√¢‚Äö¬¨√Ç¬¶   \n",
              "\n",
              "              tweetid  \n",
              "0  792927353886371840  \n",
              "1  793124211518832641  \n",
              "2  793124402388832256  \n",
              "3  793124635873275904  \n",
              "4  793125156185137153  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e42e8da6-a636-45bb-8f69-01328ee21830\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>@tiniebeany climate change is an interesting hustle as it was global warming but the planet stopped warming for 15 yes while the suv boom</td>\n",
              "      <td>792927353886371840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @NatGeoChannel: Watch #BeforeTheFlood right here, as @LeoDiCaprio travels the world to tackle climate change https://t.co/LkDehj3tNn htt√É¬¢√¢‚Äö¬¨√Ç¬¶</td>\n",
              "      <td>793124211518832641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Fabulous! Leonardo #DiCaprio's film on #climate change is brilliant!!! Do watch. https://t.co/7rV6BrmxjW via @youtube</td>\n",
              "      <td>793124402388832256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @Mick_Fanning: Just watched this amazing documentary by leonardodicaprio on climate change. We all think this√É¬¢√¢‚Äö¬¨√Ç¬¶ https://t.co/kNSTE8K8im</td>\n",
              "      <td>793124635873275904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @cnalive: Pranita Biswasi, a Lutheran from Odisha, gives testimony on effects of climate change &amp;amp; natural disasters on the po√É¬¢√¢‚Äö¬¨√Ç¬¶</td>\n",
              "      <td>793125156185137153</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e42e8da6-a636-45bb-8f69-01328ee21830')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e42e8da6-a636-45bb-8f69-01328ee21830 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e42e8da6-a636-45bb-8f69-01328ee21830');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 43943,\n  \"fields\": [\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 2,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          0,\n          -1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41033,\n        \"samples\": [\n          \"RT @AP: The Latest: President Trump to announce the US is withdrawing from the Paris climate change accord. https://t.co/f5RvFQzARj\",\n          \"RT @morten: @realDonaldTrump This is climate change, Mr. President. It affects us all whether or not you believe in it.\",\n          \"RT @amayawful: this is called 'climate change' or aka 'our planet is dying hastily' https://t.co/OX4WbkM15V\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweetid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 85685059334745632,\n        \"min\": 592633384804966400,\n        \"max\": 966702372134293504,\n        \"num_unique_values\": 43943,\n        \"samples\": [\n          955713180684177408,\n          861896636313817089,\n          839961977766178817\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xabRJNgAhZRz"
      },
      "source": [
        "Now we can see the first few records and how the sentiment is distribuited.\n",
        "\n",
        "<br>\n",
        "\n",
        "> üèÉ **Run the cell below** to view the distribution of labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24CslU4GhZRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "outputId": "614ffe48-1a19-41d6-f4ea-9ab131f11141"
      },
      "source": [
        "sentiment_map = {\n",
        "    2: \"news\",\n",
        "    1: \"pro\",\n",
        "    0: \"neutral\",\n",
        "    -1: \"anti\"\n",
        "}\n",
        "\n",
        "df[\"sentiment_text\"] = df[\"sentiment\"].map(sentiment_map)\n",
        "\n",
        "df['sentiment_text'].value_counts().plot(title='label distribution', kind='bar', color=['green', 'blue', 'gray', 'orange'])\n",
        "\n",
        "plt.xlabel(\"sentiment label\")\n",
        "plt.ylabel(\"tweet count\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1035390189.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label distribution'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'green'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'orange'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentiment label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tweet count\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IPAqB1IhZRz"
      },
      "source": [
        "‚ú¥\n",
        "\n",
        "### **3.2 Data preprocessing and cleaning**\n",
        "\n",
        "We will be dropping URLs, retweet prefixes, and non-ASCII characters to reduce platform-specific noise and standardise the text for analysis. This will have the effect of removing entities who are being tweeted at, rather than mentioned, and hopefully make the data easier for the LLMs to process.\n",
        "\n",
        "<br>\n",
        "\n",
        "> üèÉ **Run the cell below** to clean the tweets and view the cleaned text in our dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnsZrTgchZR0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "3ea79db7-b985-4f9f-f69c-a1fa3bfaa24d"
      },
      "source": [
        "# remove urls\n",
        "df['clean_message'] = df['message'].str.replace(r'http\\S+|www\\S+', '', regex=True)\n",
        "\n",
        "# remove handle after 'RT @'\n",
        "df['clean_message'] = df['clean_message'].str.replace(r'^RT\\s+@\\w+:\\s*', '', regex=True)\n",
        "\n",
        "# remove hashes (but not the whole hashtag)\n",
        "df['clean_message'] = df['clean_message'].str.replace('#', '', regex=True)\n",
        "\n",
        "# remove &amp;\n",
        "df['clean_message'] = df['clean_message'].str.replace('&amp;', 'and', regex=True)\n",
        "\n",
        "# drop ascii characters\n",
        "df['clean_message'] = df['clean_message'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
        "\n",
        "# remove @ symbols\n",
        "df['clean_message'] = df['clean_message'].str.replace('@', '', regex=True)\n",
        "\n",
        "df[['message', 'clean_message']].head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                              message  \\\n",
              "0           @tiniebeany climate change is an interesting hustle as it was global warming but the planet stopped warming for 15 yes while the suv boom   \n",
              "1  RT @NatGeoChannel: Watch #BeforeTheFlood right here, as @LeoDiCaprio travels the world to tackle climate change https://t.co/LkDehj3tNn htt√É¬¢√¢‚Äö¬¨√Ç¬¶   \n",
              "2                               Fabulous! Leonardo #DiCaprio's film on #climate change is brilliant!!! Do watch. https://t.co/7rV6BrmxjW via @youtube   \n",
              "3     RT @Mick_Fanning: Just watched this amazing documentary by leonardodicaprio on climate change. We all think this√É¬¢√¢‚Äö¬¨√Ç¬¶ https://t.co/kNSTE8K8im   \n",
              "4         RT @cnalive: Pranita Biswasi, a Lutheran from Odisha, gives testimony on effects of climate change &amp; natural disasters on the po√É¬¢√¢‚Äö¬¨√Ç¬¶   \n",
              "\n",
              "                                                                                                                              clean_message  \n",
              "0  tiniebeany climate change is an interesting hustle as it was global warming but the planet stopped warming for 15 yes while the suv boom  \n",
              "1                                           Watch BeforeTheFlood right here, as LeoDiCaprio travels the world to tackle climate change  htt  \n",
              "2                                               Fabulous! Leonardo DiCaprio's film on climate change is brilliant!!! Do watch.  via youtube  \n",
              "3                                           Just watched this amazing documentary by leonardodicaprio on climate change. We all think this   \n",
              "4                     Pranita Biswasi, a Lutheran from Odisha, gives testimony on effects of climate change and natural disasters on the po  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c654670-09f3-40a3-b5b8-fb5a6b7afcf0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>clean_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@tiniebeany climate change is an interesting hustle as it was global warming but the planet stopped warming for 15 yes while the suv boom</td>\n",
              "      <td>tiniebeany climate change is an interesting hustle as it was global warming but the planet stopped warming for 15 yes while the suv boom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @NatGeoChannel: Watch #BeforeTheFlood right here, as @LeoDiCaprio travels the world to tackle climate change https://t.co/LkDehj3tNn htt√É¬¢√¢‚Äö¬¨√Ç¬¶</td>\n",
              "      <td>Watch BeforeTheFlood right here, as LeoDiCaprio travels the world to tackle climate change  htt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fabulous! Leonardo #DiCaprio's film on #climate change is brilliant!!! Do watch. https://t.co/7rV6BrmxjW via @youtube</td>\n",
              "      <td>Fabulous! Leonardo DiCaprio's film on climate change is brilliant!!! Do watch.  via youtube</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Mick_Fanning: Just watched this amazing documentary by leonardodicaprio on climate change. We all think this√É¬¢√¢‚Äö¬¨√Ç¬¶ https://t.co/kNSTE8K8im</td>\n",
              "      <td>Just watched this amazing documentary by leonardodicaprio on climate change. We all think this</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @cnalive: Pranita Biswasi, a Lutheran from Odisha, gives testimony on effects of climate change &amp;amp; natural disasters on the po√É¬¢√¢‚Äö¬¨√Ç¬¶</td>\n",
              "      <td>Pranita Biswasi, a Lutheran from Odisha, gives testimony on effects of climate change and natural disasters on the po</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c654670-09f3-40a3-b5b8-fb5a6b7afcf0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c654670-09f3-40a3-b5b8-fb5a6b7afcf0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c654670-09f3-40a3-b5b8-fb5a6b7afcf0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[['message', 'clean_message']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"RT @NatGeoChannel: Watch #BeforeTheFlood right here, as @LeoDiCaprio travels the world to tackle climate change https://t.co/LkDehj3tNn htt\\u00c3\\u00a2\\u00e2\\u201a\\u00ac\\u00c2\\u00a6\",\n          \"RT @cnalive: Pranita Biswasi, a Lutheran from Odisha, gives testimony on effects of climate change &amp; natural disasters on the po\\u00c3\\u00a2\\u00e2\\u201a\\u00ac\\u00c2\\u00a6\",\n          \"Fabulous! Leonardo #DiCaprio's film on #climate change is brilliant!!! Do watch. https://t.co/7rV6BrmxjW via @youtube\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Watch BeforeTheFlood right here, as LeoDiCaprio travels the world to tackle climate change  htt\",\n          \"Pranita Biswasi, a Lutheran from Odisha, gives testimony on effects of climate change and natural disasters on the po\",\n          \"Fabulous! Leonardo DiCaprio's film on climate change is brilliant!!! Do watch.  via youtube\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLMs can be computationally (and fiscally) expensive to run, so it is usually a good idea to **limit testing** and **prompt refinement** to a **small sample** of the data, before applying your refined prompt to the broader dataset.\n",
        "\n",
        "<br>\n",
        "\n",
        "> üèÉ **Run the cell below** select a random sample of tweets.\n"
      ],
      "metadata": {
        "id": "U6GBiRpQn91o"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofZRvyAGhZR0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "941f3e57-c6c8-4034-98dd-35059b9e05a3"
      },
      "source": [
        "# for testing -  take a sample\n",
        "df_samp = df.groupby('sentiment_text', group_keys=False).apply(lambda x: x.sample(min(len(x), 5), random_state=0))\n",
        "df_samp[['tweetid', 'clean_message', 'sentiment_text']].head(10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-380817775.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_samp = df.groupby('sentiment_text', group_keys=False).apply(lambda x: x.sample(min(len(x), 5), random_state=0))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  tweetid  \\\n",
              "21394  867499534787768321   \n",
              "30417  953980941214670851   \n",
              "15451  841154331785093120   \n",
              "12699  828320850810109952   \n",
              "9718   810472774225502209   \n",
              "15128  840642726647480324   \n",
              "31956  963717325081006082   \n",
              "36913  601352648210677761   \n",
              "24847  892042757086334976   \n",
              "11702  822935383155605504   \n",
              "\n",
              "                                                                                                                                    clean_message  \\\n",
              "21394                    Seeing liberal leaders tweet frantically about the deadly nature of climate change but not radical Islam is truly someth   \n",
              "30417                                      UMM WUT? Bill Nye claims HOT SUMMERS are proof of climate change, gets SCHOOLED on seasons  via Sam J.   \n",
              "15451  TammyOnorato go for reasons other than climate change, and it's possible that the climate has been changing independent of humans as well.   \n",
              "12699                   NOAA sr officials played fast and loose w/data in order 2 meet politically predetermined conclusion on climate change htt   \n",
              "9718                          Yet BarackObama will be hailed a hero by the climate change mental heads ITS AGAINST THE LAW,TO KILL BALD EAGLES b    \n",
              "15128                                                                 yeah global warming where ever u r at all the hot air coming from ur mouth    \n",
              "31956                                                                                                 foxandfriends Burglar : darn global warming   \n",
              "36913                                                                                                            Please stop global warming...      \n",
              "24847                                                                  D1dupre96 They probably won't bring up his past climate change predictions   \n",
              "11702                                                 Charlie Clark talks Uber, climate change and fentanyl at mayors' meeting with Trudeau  uber   \n",
              "\n",
              "      sentiment_text  \n",
              "21394           anti  \n",
              "30417           anti  \n",
              "15451           anti  \n",
              "12699           anti  \n",
              "9718            anti  \n",
              "15128        neutral  \n",
              "31956        neutral  \n",
              "36913        neutral  \n",
              "24847        neutral  \n",
              "11702        neutral  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd30f6b4-9115-447e-9710-a769f752393b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweetid</th>\n",
              "      <th>clean_message</th>\n",
              "      <th>sentiment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21394</th>\n",
              "      <td>867499534787768321</td>\n",
              "      <td>Seeing liberal leaders tweet frantically about the deadly nature of climate change but not radical Islam is truly someth</td>\n",
              "      <td>anti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30417</th>\n",
              "      <td>953980941214670851</td>\n",
              "      <td>UMM WUT? Bill Nye claims HOT SUMMERS are proof of climate change, gets SCHOOLED on seasons  via Sam J.</td>\n",
              "      <td>anti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15451</th>\n",
              "      <td>841154331785093120</td>\n",
              "      <td>TammyOnorato go for reasons other than climate change, and it's possible that the climate has been changing independent of humans as well.</td>\n",
              "      <td>anti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12699</th>\n",
              "      <td>828320850810109952</td>\n",
              "      <td>NOAA sr officials played fast and loose w/data in order 2 meet politically predetermined conclusion on climate change htt</td>\n",
              "      <td>anti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9718</th>\n",
              "      <td>810472774225502209</td>\n",
              "      <td>Yet BarackObama will be hailed a hero by the climate change mental heads ITS AGAINST THE LAW,TO KILL BALD EAGLES b</td>\n",
              "      <td>anti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15128</th>\n",
              "      <td>840642726647480324</td>\n",
              "      <td>yeah global warming where ever u r at all the hot air coming from ur mouth</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31956</th>\n",
              "      <td>963717325081006082</td>\n",
              "      <td>foxandfriends Burglar : darn global warming</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36913</th>\n",
              "      <td>601352648210677761</td>\n",
              "      <td>Please stop global warming...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24847</th>\n",
              "      <td>892042757086334976</td>\n",
              "      <td>D1dupre96 They probably won't bring up his past climate change predictions</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11702</th>\n",
              "      <td>822935383155605504</td>\n",
              "      <td>Charlie Clark talks Uber, climate change and fentanyl at mayors' meeting with Trudeau  uber</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd30f6b4-9115-447e-9710-a769f752393b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dd30f6b4-9115-447e-9710-a769f752393b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dd30f6b4-9115-447e-9710-a769f752393b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_samp[['tweetid', 'clean_message', 'sentiment_text']]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"tweetid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 99981744484515632,\n        \"min\": 601352648210677761,\n        \"max\": 963717325081006082,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          892042757086334976,\n          953980941214670851,\n          840642726647480324\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"D1dupre96 They probably won't bring up his past climate change predictions\",\n          \"UMM WUT? Bill Nye claims HOT SUMMERS are proof of climate change, gets SCHOOLED on seasons  via Sam J.\",\n          \"yeah global warming where ever u r at all the hot air coming from ur mouth \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"neutral\",\n          \"anti\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-S-z36ehZR0"
      },
      "source": [
        "‚ú¥\n",
        "\n",
        "### **3.3 Building the infrustructure**\n",
        "\n",
        "While we have the data and the models, we need the code to make them interact\n",
        "with each other. So, before we start writing prompts, we need to have a look at\n",
        "how we can make the LLM interact with the data in a clean and reproducible way.\n",
        "\n",
        "The first thing to do is build a response format. Think of this as **the form that\n",
        "the LLM will fill out** when we ask it to look at tweet. In our example, we are\n",
        "asking the LLM to identify the **hero**, the **villain** and the **victim** in each tweet, so\n",
        "our response format will look something like this:\n",
        "\n",
        "<br>\n",
        "\n",
        "> üèÉ **Run the cell below** to define our **response format**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W5h893HhZR0"
      },
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import Optional\n",
        "\n",
        "class ResponseFormat(BaseModel):\n",
        "    hero: Optional[str] = None\n",
        "    victim: Optional[str] = None\n",
        "    villain: Optional[str] = None"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4PZQYqXhZR1"
      },
      "source": [
        "The second thing we need is a new **function** that can use this response format and feed the data to the model.\n",
        "\n",
        "<br>\n",
        "\n",
        "> üèÉ **Run the cell below** to define our new function. Again, this will not 'do' anything just yet, but we will **call** it in a moment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3QQ2HIuhZR1"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def query_llm_prompting(df_samp, mymodel, response_format, prompt):\n",
        "    # make a copy so the original df_samp is untouched\n",
        "    df_result = df_samp.copy()\n",
        "\n",
        "    # get the columns from the response format\n",
        "    cols = response_format.__fields__.keys()\n",
        "    for col in cols:\n",
        "        df_result[col] = None\n",
        "\n",
        "    # iterate through each row in the dataframe\n",
        "    for idx, row in tqdm(df_result.iterrows(), total=len(df_result)):\n",
        "        response = ollama.chat(\n",
        "            model=mymodel,\n",
        "            messages=[\n",
        "                {'role': 'system', 'content': prompt},\n",
        "                {'role': 'user', 'content': row['clean_message']}\n",
        "            ],\n",
        "            format=response_format.model_json_schema(),\n",
        "        )\n",
        "\n",
        "        # extract text from full response\n",
        "        parsed_response = response_format.model_validate_json(response.message.content)\n",
        "\n",
        "        for col in cols:\n",
        "            df_result.at[idx, col] = getattr(parsed_response, col)\n",
        "\n",
        "\n",
        "    return df_result"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# def transform_data(df, model, response_format, prompt, think = False):\n",
        "#     cols = response_format.__fields__.keys()\n",
        "#     for col in cols:\n",
        "#         df[col] = None\n",
        "#     if think:\n",
        "#         df['reasoning'] = None\n",
        "\n",
        "#     for idx, row in tqdm(df.iterrows()):\n",
        "#         response = ollama.chat(\n",
        "#             model=model,\n",
        "#             messages=[{'role': 'system', 'content': prompt}, {'role': 'user',\n",
        "#             'content': row['clean_message']}],\n",
        "#             format=response_format.model_json_schema(),\n",
        "#             think = think\n",
        "#         )\n",
        "#         parsed_response = response_format.model_validate_json(response.message.content)\n",
        "#         for col in cols:\n",
        "#             df.at[idx, col] = getattr(parsed_response, col)\n",
        "#         if think:\n",
        "#             df.at[idx, 'reasoning'] = response.message.thinking\n",
        "\n",
        "#     return df"
      ],
      "metadata": {
        "id": "RtHRYcFpoLxl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjeBKND3hZR1"
      },
      "source": [
        "---\n",
        "# **üîß Part 4. Prompt engineering**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ú¥\n",
        "\n",
        "### **4.1 Model Selection**\n",
        "In this section, we will work into groups and each run a pre-determined model, developing and refining our prompt as we go. We will then take a few minutes to discuss the differences in the outputs between each model.\n",
        "\n",
        "<br>\n",
        "\n",
        "> üèÉ **Run the cell below** to select your model."
      ],
      "metadata": {
        "id": "kAloeeV1InNZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHAubqq9hZR1",
        "outputId": "6829d049-69fc-4641-ff1d-2341929bd5ef"
      },
      "source": [
        "mymodel = 'llama3.1:8b'\n",
        "print(f\"Using model:\\n\\n {model}\\n\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using model:\n",
            "\n",
            " llama3.1:8b\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR7Ht5kXhZR2"
      },
      "source": [
        "### **4.2 Zero-shot prompting**\n",
        "\n",
        "**Zero-shot prompting** is the form of LLM prompting that benefits only from the **knowledge contained within the LLM itself**. Instructions are provided, with no examples of the desired output.\n",
        "\n",
        "<br>\n",
        "\n",
        "> üèÉ **Run the cell below** to define your zero-shot prompt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cd8PoWxhZR2"
      },
      "source": [
        "prompt_zeroshot = '''\n",
        "You are a helpful research assistant, interested in the framing of narratives in tweets about climate change. You have been tasked with identifying the heroes, villains and victims in a selection of tweets.\n",
        "Task: Read each tweet and decide if there is a hero, a villain or a victim, as per the following criteria:\n",
        "\n",
        "Hero: an entity contributing to/responsible for issue resolution\n",
        "Villain: an entity contributing to/responsible for issue cause\n",
        "Victim: an entity suffering the consequences of an issue\n",
        "\n",
        "Extract from the text the names of entities (people, groups, organisations) that are explicitly  or implicitly framed as either heroes, victims or villains. Do not make your own interpretations. If there is no hero, villain, or victim, respond with 'none'.\n",
        "'''"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "> üèÉ **Run the cell below** to pass this **zero-shot prompt** to the model, and view the response."
      ],
      "metadata": {
        "id": "pOLttRQoripE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWktFcgchZR2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "e71e762b-3fbc-4971-f1e7-ce988286cf72"
      },
      "source": [
        "response_format = ResponseFormat()\n",
        "response_df_zeroshot = query_llm_prompting(df_samp, mymodel, response_format, prompt=prompt_zeroshot)\n",
        "# response_df_zeroshot = transform_data(df_samp, mymodel, response_format, prompt=prompt_zeroshot)\n",
        "\n",
        "\n",
        "response_df_zeroshot[['clean_message', 'hero', 'villain', 'victim']]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4254469634.py:8: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use the `model_fields` class property instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  cols = response_format.__fields__.keys()\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:25<00:00,  1.28s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                    clean_message  \\\n",
              "21394                    Seeing liberal leaders tweet frantically about the deadly nature of climate change but not radical Islam is truly someth   \n",
              "30417                                      UMM WUT? Bill Nye claims HOT SUMMERS are proof of climate change, gets SCHOOLED on seasons  via Sam J.   \n",
              "15451  TammyOnorato go for reasons other than climate change, and it's possible that the climate has been changing independent of humans as well.   \n",
              "12699                   NOAA sr officials played fast and loose w/data in order 2 meet politically predetermined conclusion on climate change htt   \n",
              "9718                          Yet BarackObama will be hailed a hero by the climate change mental heads ITS AGAINST THE LAW,TO KILL BALD EAGLES b    \n",
              "15128                                                                 yeah global warming where ever u r at all the hot air coming from ur mouth    \n",
              "31956                                                                                                 foxandfriends Burglar : darn global warming   \n",
              "36913                                                                                                            Please stop global warming...      \n",
              "24847                                                                  D1dupre96 They probably won't bring up his past climate change predictions   \n",
              "11702                                                 Charlie Clark talks Uber, climate change and fentanyl at mayors' meeting with Trudeau  uber   \n",
              "30477                                               Sweden to issue updated 1940s 'war guide' amid threats of terrorism and climate change  News    \n",
              "15196                                                     EPA flooded with phone calls after EPA head denies CO2 role in climate change: report     \n",
              "35380                                                                       CO2 removal 'no silver bullet' to fighting climate change-scientists    \n",
              "38066                                              Scientists find 6 million year old fossil that could hold key to prehistoric climate change:     \n",
              "23114                                                             The fight against climate change: four cities leading the way in the Trump era    \n",
              "43291                                                       One Look at These Images and You$q$ll Be Certain That Climate Change Is For Real...     \n",
              "14490                                 The only way to defend Sudan against climate change is through education. Trumps ban cuts us off from that    \n",
              "26532                                                                                                 You climate change deniers really scare me.   \n",
              "9865                                                                              clarebuttner Santa, unlike climate change, is a made up notion!   \n",
              "14135                          Breaking: EPA Chief says carbon dioxide not a primary contributor to global warming, denies scientific consensus.    \n",
              "\n",
              "               hero                 villain victim  \n",
              "21394          None         liberal leaders   None  \n",
              "30417          None                Bill Nye   None  \n",
              "15451          None     Humans (implicitly)   None  \n",
              "12699          None       NOAA sr officials   None  \n",
              "9718   Barack Obama                    None   None  \n",
              "15128          None                     you   None  \n",
              "31956          None          global warming   None  \n",
              "36913          None                    None   None  \n",
              "24847          None                    None   None  \n",
              "11702          None                    Uber   None  \n",
              "30477          None                    None   None  \n",
              "15196          None                    None   None  \n",
              "35380          None          climate change   None  \n",
              "38066    Scientists                    none   None  \n",
              "23114   four cities                    None   None  \n",
              "43291          None                    None   None  \n",
              "14490          None                    None  Sudan  \n",
              "26532          None  climate change deniers   None  \n",
              "9865           None                    None   None  \n",
              "14135          None               EPA Chief   None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d41caf1-df5f-4567-8fdb-0491a029484b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_message</th>\n",
              "      <th>hero</th>\n",
              "      <th>villain</th>\n",
              "      <th>victim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21394</th>\n",
              "      <td>Seeing liberal leaders tweet frantically about the deadly nature of climate change but not radical Islam is truly someth</td>\n",
              "      <td>None</td>\n",
              "      <td>liberal leaders</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30417</th>\n",
              "      <td>UMM WUT? Bill Nye claims HOT SUMMERS are proof of climate change, gets SCHOOLED on seasons  via Sam J.</td>\n",
              "      <td>None</td>\n",
              "      <td>Bill Nye</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15451</th>\n",
              "      <td>TammyOnorato go for reasons other than climate change, and it's possible that the climate has been changing independent of humans as well.</td>\n",
              "      <td>None</td>\n",
              "      <td>Humans (implicitly)</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12699</th>\n",
              "      <td>NOAA sr officials played fast and loose w/data in order 2 meet politically predetermined conclusion on climate change htt</td>\n",
              "      <td>None</td>\n",
              "      <td>NOAA sr officials</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9718</th>\n",
              "      <td>Yet BarackObama will be hailed a hero by the climate change mental heads ITS AGAINST THE LAW,TO KILL BALD EAGLES b</td>\n",
              "      <td>Barack Obama</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15128</th>\n",
              "      <td>yeah global warming where ever u r at all the hot air coming from ur mouth</td>\n",
              "      <td>None</td>\n",
              "      <td>you</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31956</th>\n",
              "      <td>foxandfriends Burglar : darn global warming</td>\n",
              "      <td>None</td>\n",
              "      <td>global warming</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36913</th>\n",
              "      <td>Please stop global warming...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24847</th>\n",
              "      <td>D1dupre96 They probably won't bring up his past climate change predictions</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11702</th>\n",
              "      <td>Charlie Clark talks Uber, climate change and fentanyl at mayors' meeting with Trudeau  uber</td>\n",
              "      <td>None</td>\n",
              "      <td>Uber</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30477</th>\n",
              "      <td>Sweden to issue updated 1940s 'war guide' amid threats of terrorism and climate change  News</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15196</th>\n",
              "      <td>EPA flooded with phone calls after EPA head denies CO2 role in climate change: report</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35380</th>\n",
              "      <td>CO2 removal 'no silver bullet' to fighting climate change-scientists</td>\n",
              "      <td>None</td>\n",
              "      <td>climate change</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38066</th>\n",
              "      <td>Scientists find 6 million year old fossil that could hold key to prehistoric climate change:</td>\n",
              "      <td>Scientists</td>\n",
              "      <td>none</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23114</th>\n",
              "      <td>The fight against climate change: four cities leading the way in the Trump era</td>\n",
              "      <td>four cities</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43291</th>\n",
              "      <td>One Look at These Images and You$q$ll Be Certain That Climate Change Is For Real...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14490</th>\n",
              "      <td>The only way to defend Sudan against climate change is through education. Trumps ban cuts us off from that</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Sudan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26532</th>\n",
              "      <td>You climate change deniers really scare me.</td>\n",
              "      <td>None</td>\n",
              "      <td>climate change deniers</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9865</th>\n",
              "      <td>clarebuttner Santa, unlike climate change, is a made up notion!</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14135</th>\n",
              "      <td>Breaking: EPA Chief says carbon dioxide not a primary contributor to global warming, denies scientific consensus.</td>\n",
              "      <td>None</td>\n",
              "      <td>EPA Chief</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d41caf1-df5f-4567-8fdb-0491a029484b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5d41caf1-df5f-4567-8fdb-0491a029484b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5d41caf1-df5f-4567-8fdb-0491a029484b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"response_df_zeroshot[['clean_message', 'hero', 'villain', 'victim']]\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"clean_message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Seeing liberal leaders tweet frantically about the deadly nature of climate change but not radical Islam is truly someth\",\n          \"You climate change deniers really scare me.\",\n          \"One Look at These Images and You$q$ll Be Certain That Climate Change Is For Real...  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hero\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Barack Obama\",\n          \"four cities\",\n          \"None\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"villain\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"climate change deniers\",\n          \"none\",\n          \"liberal leaders\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"victim\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Sudan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**While this runs:**\n",
        "\n",
        "‚úã Who is the 'helpful research assitant'?\n",
        "\n",
        "‚úã What knowledge is the language model drawing from?\n",
        "\n"
      ],
      "metadata": {
        "id": "Vq_I-_AGjp90"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWqEXOjkhZR2"
      },
      "source": [
        "### **4.3 Few-shot prompting**\n",
        "\n",
        "**Few-shot prompting** is a prompting technique in which a small number of examples of the desired output are provided, to give the model an opportunity to learn patterns and follow these in the output.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "> üèÉ **Run the cell below** to define your zero-shot prompt. Notice that the examples provided give a clear image of the expected output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVaTzzKvhZR2"
      },
      "source": [
        "prompt_fewshot = '''\n",
        "You are a helpful research assistant, interested in the framing of narratives in tweets about climate change. You have been tasked with identifying the heroes, villains and victims in a selection of tweets.\n",
        "Task: Read each tweet and decide if there is a hero, a villain or a victim, as per the following criteria:\n",
        "\n",
        "Hero: an entity contributing to/responsible for issue resolution\n",
        "Villain: an entity contributing to/responsible for issue cause\n",
        "Victim: an entity suffering the consequences of an issue\n",
        "\n",
        "Examples:\n",
        "1. Theresa May's new chief of staff, Gavin Barwell, is known for his knowledgable concern about climate change\n",
        "    hero: Gavin Barwell\n",
        "    victim: None\n",
        "    villain: None\n",
        "\n",
        "2. The reality of climate change impacts everyone but the truth is that poor communities suffer most...perpetuating the injustice\n",
        "    hero: None\n",
        "    victim: poor communities\n",
        "    villain: climate change\n",
        "\n",
        "3. Anti-Trump actor fights global warming, but wont give up 14 homes and private jet\n",
        "    hero: Anti-Trump actor\n",
        "    victim: None\n",
        "    villain: Anti-Trump actor\n",
        "\n",
        "Extract from the text the names of entities (people, groups, organisations) that are explicitly or implicitly framed as either heroes, victims or villains. Do not make your own interpretations. If there is no hero, villain, or victim, respond with 'none'.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "> üèÉ **Run the cell below** to pass this **few-shot prompt** to the model, and view the response."
      ],
      "metadata": {
        "id": "HhsqzyYk32kS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWzWr_u3hZR3"
      },
      "source": [
        "response_df_fewshot = query_llm_prompting(df_samp, mymodel, response_format, prompt=prompt_fewshot)\n",
        "\n",
        "response_df_fewshot[['clean_message', 'hero', 'villain', 'victim']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**While this runs:**\n",
        "\n",
        "‚úã Where do our examples come from?\n",
        "\n",
        "‚úã How do we define our gold standard answers?\n",
        "\n",
        "‚úã Could this bias the LLMs responses, and how?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eX0ahDqajtAE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQeFFcjohZR3"
      },
      "source": [
        "### **4.4 Chain-of-thought reasoning**\n",
        "\n",
        "**Chain-of-thought reasoning** is a prompting technique that guides the LLM through the task step-by-step, providing a logical flow for the analysis, as well as examples. It is common also to have the LLM provide some sort of justification for its response, which is useful for interpretability.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xninWUjMhZR3"
      },
      "source": [
        "prompt_cot = '''\n",
        "You are a helpful research assistant, interested in the framing of narratives in tweets about climate change. You have been tasked with identifying the heroes, villains and victims in a selection of tweets.\n",
        "Task:\n",
        "Read each tweet and decide if there is a hero, a villain or a victim, as per the following criteria:\n",
        "\n",
        "Hero: an entity contributing to/responsible for issue resolution\n",
        "Villain: an entity contributing to/responsible for issue cause\n",
        "Victim: an entity suffering the consequences of an issue\n",
        "\n",
        "Examples:\n",
        "1. Theresa May's new chief of staff, Gavin Barwell, is known for his knowledgable concern about climate change\n",
        "    hero: Gavin Barwell\n",
        "    victim: None\n",
        "    villain: None\n",
        "\n",
        "2. The reality of climate change impacts everyone but the truth is that poor communities suffer most...perpetuating the injustice\n",
        "    hero: None\n",
        "    victim: poor communities\n",
        "    villain: climate change\n",
        "\n",
        "3. Anti-Trump actor fights global warming, but wont give up 14 homes and private jet\n",
        "    hero: Anti-Trump actor\n",
        "    victim: None\n",
        "    villain: Anti-Trump actor\n",
        "\n",
        "Chain of thought:\n",
        "1. Identify the central issue: Determine what climate-related problem or event the tweet is discussing.\n",
        "2. Look for conflict or tension: Check if the tweet highlights a problem, blame, praise, or action.\n",
        "3. Detect heroes: Identify entities praised for mitigating or solving the issue.\n",
        "4. Detect victims: Identify entities suffering negative consequences of the issue.\n",
        "5. Detect villains: Identify entities blamed for causing or worsening the issue.\n",
        "\n",
        "Extract from the text the names of entities (people, groups, organisations) that are explicitly or implicitly framed as either heroes, victims or villains. Do not make your own interpretations. If there is no hero, villain, or victim, respond with 'none'.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "> üèÉ **Run the cell below** to pass this **chain-of-thought prompt** to the model, and view the response."
      ],
      "metadata": {
        "id": "jC_Q6IavI_mU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SzErNO6hZR3"
      },
      "source": [
        "class CoT_ResponseFormat(BaseModel):\n",
        "    hero: Optional[str] = None\n",
        "    victim: Optional[str] = None\n",
        "    villain: Optional[str] = None\n",
        "    reasoning: Optional[str] = None\n",
        "\n",
        "response_format = CoT_ResponseFormat()\n",
        "response_df_cot = query_llm_prompting(df_samp, mymodel, response_format, prompt=prompt_cot)\n",
        "\n",
        "response_df_cot[['clean_message', 'hero', 'villain', 'victim', 'reasoning']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**While this runs:**\n",
        "\n",
        "‚úã Who is the 'helpful research assitant'?\n",
        "\n",
        "‚úã What knowledge is the language model drawing from?\n",
        "\n",
        "‚úã\n",
        "\n",
        "‚úã\n"
      ],
      "metadata": {
        "id": "pKthiyBujSVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_df.columns"
      ],
      "metadata": {
        "id": "DyIEy9TdRCmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot whether a hero, villain or victim was found in each df\n",
        "\n",
        "# combine response_dfs with column for prompt_type\n",
        "response_df_zeroshot['prompt_type'] = 'zeroshot'\n",
        "response_df_fewshot['prompt_type'] = 'fewshot'\n",
        "response_df_cot['prompt_type'] = 'cot'\n",
        "\n",
        "# concat vertically\n",
        "response_df = pd.concat([response_df_zeroshot, response_df_fewshot, response_df_cot])\n",
        "response_df.sort_values(by='tweetid')"
      ],
      "metadata": {
        "id": "g2PX3uGU-fcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "# Copy and lowercase columns first\n",
        "df = response_df.copy()\n",
        "df.columns = [c.lower() for c in df.columns]\n",
        "\n",
        "outcomes = ['hero', 'villain', 'victim']\n",
        "\n",
        "def clean_empty(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    if isinstance(x, str) and x.strip().lower() in ['none', 'null', 'nulle', '']:\n",
        "        return np.nan\n",
        "    return x\n",
        "\n",
        "df[outcomes] = df[outcomes].applymap(clean_empty)\n",
        "\n",
        "df_long = df.melt(\n",
        "    id_vars=['tweetid', 'prompt_type', 'clean_message'],\n",
        "    value_vars=outcomes,\n",
        "    var_name='outcome',\n",
        "    value_name='value'\n",
        ")\n",
        "\n",
        "def wrap_text(text, width=50):\n",
        "    return \"\\n\".join(textwrap.wrap(str(text), width))\n",
        "\n",
        "df_long['tweet_label'] = (\n",
        "    df_long['tweetid'].astype(str)\n",
        "    + \":\\n\"\n",
        "    + df_long['clean_message'].apply(lambda x: wrap_text(x, 50))\n",
        ")\n",
        "\n",
        "prompt_types = list(df['prompt_type'].dropna().unique())\n",
        "\n",
        "# --- FIGURE SIZE: make subplots wider ---\n",
        "subplot_width = 6\n",
        "fig, axes = plt.subplots(\n",
        "    nrows=1,\n",
        "    ncols=len(prompt_types),\n",
        "    figsize=(subplot_width * len(prompt_types),\n",
        "             len(df['tweetid'].unique()) * 1.2),\n",
        "    sharey=True\n",
        ")\n",
        "\n",
        "# Make axes iterable if only one subplot\n",
        "if len(prompt_types) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, prompt in enumerate(prompt_types):\n",
        "    df_prompt = df_long[df_long['prompt_type'] == prompt].copy()\n",
        "\n",
        "    # If nothing for this prompt, show empty panel\n",
        "    if df_prompt.empty:\n",
        "        axes[i].set_title(str(prompt))\n",
        "        axes[i].axis(\"off\")\n",
        "        axes[i].text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\")\n",
        "        continue\n",
        "\n",
        "    # Pivot for presence (color)\n",
        "    df_presence = df_prompt.pivot_table(\n",
        "        index='tweet_label',\n",
        "        columns='outcome',\n",
        "        values='value',\n",
        "        aggfunc=lambda x: x.notna().any()\n",
        "    )\n",
        "\n",
        "    # Pivot for annotations (text)\n",
        "    df_text = df_prompt.pivot_table(\n",
        "        index='tweet_label',\n",
        "        columns='outcome',\n",
        "        values='value',\n",
        "        aggfunc=lambda x: next((v for v in x if pd.notna(v)), np.nan)\n",
        "    )\n",
        "\n",
        "    # Force all columns to exist\n",
        "    df_presence = df_presence.reindex(columns=outcomes, fill_value=False)\n",
        "    df_text = df_text.reindex(columns=outcomes)\n",
        "\n",
        "    # Force both to have same row index\n",
        "    df_text = df_text.reindex(index=df_presence.index)\n",
        "\n",
        "    annot = df_text.fillna(\"\")\n",
        "\n",
        "    sns.heatmap(\n",
        "        df_presence,\n",
        "        ax=axes[i],\n",
        "        cmap=['lightgrey', 'green'],\n",
        "        cbar=False,\n",
        "        linewidths=0.5,\n",
        "        linecolor='black',\n",
        "        annot=annot,\n",
        "        fmt=\"\",\n",
        "        annot_kws={\"size\": 9}\n",
        "    )\n",
        "\n",
        "    axes[i].set_title(str(prompt))\n",
        "    axes[i].set_xlabel(\"Outcome\")\n",
        "    if i == 0:\n",
        "        axes[i].set_ylabel(\"Tweet ID & Message\")\n",
        "    else:\n",
        "        axes[i].set_ylabel(\"\")\n",
        "\n",
        "plt.suptitle(\"Values for Each Prompt Type Across Outcomes per Tweet\", fontsize=16, y=1.05)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.subplots_adjust(wspace=0.3)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HNk3BsfcReud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCEKV4gohZR4"
      },
      "source": [
        "### **4.5 Classifying our Roles**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLc_SB_KhZR4"
      },
      "source": [
        "from typing import Literal\n",
        "\n",
        "ActorType = Literal[\n",
        "    \"ENVIRONMENT\",\n",
        "    \"CLIMATECHANGE\",\n",
        "    \"ENVIROMENTAL_ACTIVISTS\",\n",
        "    \"GENERAL_PUBLIC\",\n",
        "    \"GOVERNMENTS_AND_POLITICIANS\",\n",
        "    \"GREEN_TECHNOLOGY\",\n",
        "    \"INDUSTRY\",\n",
        "    \"EMISSIONS\",\n",
        "    \"LEGISLATION_AND_POLICY\",\n",
        "    \"MEDIA\",\n",
        "    \"SCIENCE_AND_EXPERTS\",\n",
        "]\n",
        "class ClassificationResponseFormat(BaseModel):\n",
        "    hero: Optional[str] = None\n",
        "    hero_type: Optional[ActorType] = None\n",
        "    victim: Optional[str] = None\n",
        "    victim_type: Optional[ActorType] = None\n",
        "    villain: Optional[str] = None\n",
        "    villain_type: Optional[ActorType] = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbGMaBMihZR4"
      },
      "source": [
        "prompt_cot = '''\n",
        "You are a helpful research assistant, interested in the framing of narratives in tweets about climate change. You have been tasked with identifying the heroes, villains and victims in a selection of tweets.\n",
        "Task:\n",
        "Read each tweet and decide if there is a hero, a villain or a victim, as per the following criteria:\n",
        "\n",
        "Hero: an entity contributing to/responsible for issue resolution\n",
        "Villain: an entity contributing to/responsible for issue cause\n",
        "Victim: an entity suffering the consequences of an issue\n",
        "\n",
        "Chain of thought:\n",
        "1. Identify the central issue: Determine what climate-related problem or event the tweet is discussing.\n",
        "2. Look for conflict or tension: Check if the tweet highlights a problem, blame, praise, or action.\n",
        "3. Detect heroes: Identify entities praised for mitigating or solving the issue.\n",
        "4. Detect victims: Identify entities suffering negative consequences of the issue.\n",
        "5. Detect villains: Identify entities blamed for causing or worsening the issue.\n",
        "6. Identify Roles: For any identified actors, assign them one of the available types to the best of your ability. Only assing roles if you have identified an actor. Any identified actor will have an allocated type\n",
        "\n",
        "Actor Types:\n",
        "    \"ENVIRONMENT\": The natural world including ecosystems, wildlife, and natural resources.\n",
        "    \"CLIMATE_CHANGE\": Long-term changes in temperature, precipitation, and weather patterns caused by human activities.\n",
        "    \"ENVIRONMENTAL_ACTIVISTS\": Individuals or groups advocating for environmental protection and sustainability.\n",
        "    \"GENERAL_PUBLIC\": The broad populations, communities, or individuals affected by or involved in environmental issues.\n",
        "    \"GOVERNMENTS_AND_POLITICIANS\": Authorities and elected officials responsible for creating and enforcing laws and policies.\n",
        "    \"GREEN_TECHNOLOGY\": Innovations and technologies aimed at reducing environmental impact and promoting sustainability.\n",
        "    \"INDUSTRY\": Businesses and sectors involved in production, manufacturing, and economic activities impacting the environment.\n",
        "    \"EMISSIONS\": Release of pollutants or greenhouse gases into the atmosphere from various sources.\n",
        "    \"LEGISLATION_AND_POLICY\": Laws, regulations, and guidelines designed to manage environmental and climate-related issues.\n",
        "    \"MEDIA\": Channels and platforms that disseminate information and shape public opinion on environmental topics.\n",
        "    \"SCIENCE_AND_EXPERTS\": Researchers and professionals providing knowledge, data, and analysis on environmental and climate matters.\n",
        "\n",
        "Examples:\n",
        "1. Theresa May's new chief of staff, Gavin Barwell, is known for his knowledgable concern about climate change\n",
        "    hero: Gavin Barwell\n",
        "    hero_type: \"GOVERNMENTS_AND_POLITICIANS\",\n",
        "\n",
        "1. The reality of climate change impacts everyone but the truth is that poor communities suffer most...perpetuating the injustice\n",
        "    victim: poor communities\n",
        "    hero_type: \"GENERAL_PUBLIC\"\n",
        "    villain: Climate Change\n",
        "    villain_type: \"CLIMATE_CHANGE\"\n",
        "\n",
        "1. Anti-Trump actor fights global warming, but wont give up 14 homes and private jet\n",
        "    hero: Anti-Trump actor\n",
        "    hero_type: \"ENVIROMENTAL_ACTIVISTS\"\n",
        "    villain: Anti-Trump actor\n",
        "    villain_type: \"ENVIROMENTAL_ACTIVISTS\"\n",
        "\n",
        "Extract from the text the names of entities (people, groups, organisations) that are explicitly framed as either heroes, victims or villains. Do not make your own interpretations. If there is no hero, villain, or victim, respond with 'none'.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VKdYoxOhZR4"
      },
      "source": [
        "response_format = ClassificationResponseFormat()\n",
        "response_df = transform_data(df_samp, model, response_format, prompt=prompt_cot)\n",
        "\n",
        "print(response_df[['clean_message', 'hero', 'villain', 'victim', 'hero_type', 'villain_type', 'victim_type']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEO2tWg2hZR4"
      },
      "source": [
        "---\n",
        "# **üîé Part 5. Comparing results**\n",
        "\n",
        "In groups, let's see how the responses differed\n",
        "\n",
        "- If you had the same models, did they respond the same?\n",
        "- If there were different models, did you see any changes between your responses?\n",
        "- If you changed the prompts, how did this change the responses?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **üìè Part 6. Quantitative Analysis**\n",
        "\"Here is one we prepared earlier\"\n",
        "* assume we are happy with our prompt\n",
        "* shows the impact of different prompting strategies on different models on much larger dataset (impractical to do in the workshop)"
      ],
      "metadata": {
        "id": "eUy6SQpJG6B_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "qwen_prebaked  = pd.read_pickle('https://github.com/Fonzzy1/LLM-Workshop/raw/refs/heads/main/qwen3:8b.pkl')\n",
        "deepseek_prebaked = pd.read_pickle('https://github.com/Fonzzy1/LLM-Workshop/raw/refs/heads/main/deepseek-r1:8b.pkl')\n",
        "gemma_prebaked = pd.read_pickle(\"https://github.com/Fonzzy1/LLM-Workshop/raw/refs/heads/main/gemma3:4b.pkl\")\n",
        "lamma_prebaked = pd.read_pickle(\"https://github.com/Fonzzy1/LLM-Workshop/raw/refs/heads/main/llama3.1:8b.pkl\")\n",
        "\n",
        "gemma_prebaked.head()"
      ],
      "metadata": {
        "id": "Sm3xVwMGG2LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68b3c14a"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add model labels\n",
        "qwen_prebaked[\"model\"] = \"Qwen3-8B\"\n",
        "deepseek_prebaked[\"model\"] = \"DeepSeek-R1-8B\"\n",
        "gemma_prebaked[\"model\"] = \"Gemma3-4B\"\n",
        "lamma_prebaked[\"model\"] = \"LLaMA3.1-8B\"\n",
        "\n",
        "# Combine\n",
        "df = pd.concat(\n",
        "    [qwen_prebaked, deepseek_prebaked, gemma_prebaked, lamma_prebaked],\n",
        "    ignore_index=True\n",
        ")\n",
        "\n",
        "# --- 3. Melt to long format ---\n",
        "long_df = df.melt(\n",
        "    id_vars=[\"tweetid\", \"model\",'sentiment','clean_message'],  # ensure tweetid is included\n",
        "    value_vars=[\"hero_type\", \"villain_type\", \"victim_type\"],\n",
        "    var_name=\"role\",\n",
        "    value_name=\"type\"\n",
        ")\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set theme\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Create catplot\n",
        "g = sns.catplot(\n",
        "    data=long_df,\n",
        "    x=\"type\",\n",
        "    hue=\"role\",          # color by role now\n",
        "    col=\"model\",         # one plot per model\n",
        "    kind=\"count\",\n",
        "    height=5,\n",
        "    aspect=1.2,\n",
        "    sharey=False,\n",
        "    palette=\"Set2\",\n",
        "    col_wrap=2           # 2x2 grid\n",
        ")\n",
        "\n",
        "# Titles and labels\n",
        "g.set_titles(\"{col_name}\")\n",
        "g.set_axis_labels(\"\", \"Count\")\n",
        "\n",
        "# Rotate x-axis labels for readability\n",
        "for ax in g.axes.flat:\n",
        "    ax.tick_params(axis='x', rotation=90)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute majority vote per tweet_id and role\n",
        "# Treat None/NaN as valid\n",
        "long_df[\"type\"] = long_df[\"type\"].where(long_df[\"type\"].notna(), None)\n",
        "\n",
        "# --- 4. Compute majority vote excluding None ---\n",
        "def majority_vote(x):\n",
        "    counts = x.value_counts(dropna=True)\n",
        "    if len(counts):  # count None as a valid option\n",
        "       return counts.idxmax()\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "majority_votes = (\n",
        "    long_df.groupby([\"tweetid\", \"role\",'sentiment','clean_message'])[\"type\"]\n",
        "    .agg(majority_vote)\n",
        "    .reset_index()\n",
        "    .rename(columns={\"type\": \"majority_type\"})\n",
        ").dropna()\n",
        "\n",
        "\n",
        "# --- 5. Plot counts based on majority votes ---\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(\n",
        "    data=majority_votes,\n",
        "    x=\"majority_type\",\n",
        "    hue=\"role\",\n",
        "    palette=\"Set2\"\n",
        ")\n",
        "\n",
        "plt.xlabel(\"\")\n",
        "plt.ylabel(\"Count (per tweet, majority vote)\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Majority Vote Counts per Type Across Roles\")\n",
        "plt.legend(title=\"Role\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ft4IUdedtZlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Majority votes already computed ---\n",
        "# majority_votes has columns: tweetid, role, sentiment, clean_message, majority_type\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Use catplot to create one plot per sentiment\n",
        "g = sns.catplot(\n",
        "    data=majority_votes,\n",
        "    x=\"majority_type\",\n",
        "    hue=\"role\",\n",
        "    col=\"sentiment\",           # one plot per sentiment\n",
        "    kind=\"count\",\n",
        "    col_wrap=2,                # 2x2 grid for 4 sentiments\n",
        "    height=5,\n",
        "    aspect=1.2,\n",
        "    palette=\"Set2\",\n",
        "    sharey=False\n",
        ")\n",
        "\n",
        "# Titles and axis labels\n",
        "g.set_titles(\"Sentiment = {col_name}\")\n",
        "g.set_axis_labels(\"\", \"Count\")\n",
        "for ax in g.axes.flat:\n",
        "    ax.tick_params(axis='x', rotation=90)  # rotate x labels for readability\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "IGqGQs3otXt9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}